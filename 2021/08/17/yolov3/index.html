<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="John Doe">





<title>yolov3 | Hexo</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Zhanghan&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Zhanghan&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">yolov3</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">John Doe</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">August 17, 2021&nbsp;&nbsp;11:40:50</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>YOLO是目标检测框架中性能比较优秀的一类，所以我把YOLO作为第一个学习的目标。在YOLO家族中也有很多版本，先选v3这个版本开始学，学通透了，其他的应该就能触类旁通了。</p>
<h1 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h1><p>首先YOLOv3采用了全卷积层，即没有使用全连接层，并且使用了大量的残差块来确保网络深度足够的同时也不会出现梯度消失的问题。</p>
<p>参考文章：</p>
<p><a target="_blank" rel="noopener" href="https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-3/">从0到1实现YOLOv3</a></p>
<p>这篇文章读取配置文件创建网络模型，然后再载入训练数据。配置文件按照前向传播的顺序记录网络结构，并且在设计残差块的相加和yolo外部网络的叠加操作时都引入空模型进行规范化。但是配置文件应该有点错误，在开头的网络信息中输入的维度不是608而应该是416。</p>
<p><img src="/2021/08/17/yolov3/1.png" alt="1"></p>
<p>下面是文章中的代码：</p>
<p>导入的库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>

<p>解析配置文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解析cfg文件，每块存储为dict</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_cfg</span>(<span class="params">cfgfile</span>):</span></span><br><span class="line">    </span><br><span class="line">    file = <span class="built_in">open</span>(cfgfile, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    lines = file.read().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    lines = [x <span class="keyword">for</span> x <span class="keyword">in</span> lines <span class="keyword">if</span> <span class="built_in">len</span>(x) &gt; <span class="number">0</span>]<span class="comment">#去除空行</span></span><br><span class="line">    lines = [x <span class="keyword">for</span> x <span class="keyword">in</span> lines <span class="keyword">if</span> x[<span class="number">0</span>] != <span class="string">&#x27;#&#x27;</span>]<span class="comment">#去除注释</span></span><br><span class="line">    lines = [x.rstrip().lstrip() <span class="keyword">for</span> x <span class="keyword">in</span> lines]<span class="comment">#去除左右空格</span></span><br><span class="line">    </span><br><span class="line">    block = &#123;&#125;</span><br><span class="line">    blocks = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="keyword">if</span> line[<span class="number">0</span>] == <span class="string">&quot;[&quot;</span>:<span class="comment">#新块的开始</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(block) != <span class="number">0</span>:</span><br><span class="line">                blocks.append(block)<span class="comment">#保存上一块</span></span><br><span class="line">                block = &#123;&#125;</span><br><span class="line">            block[<span class="string">&#x27;type&#x27;</span>] = line[<span class="number">1</span>:-<span class="number">1</span>].rstrip()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            key,value = line.split(<span class="string">&#x27;=&#x27;</span>)</span><br><span class="line">            block[key.rstrip()] = value.lstrip()</span><br><span class="line">    blocks.append(block)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> blocks</span><br></pre></td></tr></table></figure>

<p>根据解析文件的dict构建网络模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_modules</span>(<span class="params">blocks</span>):</span></span><br><span class="line">    net_info = blocks[<span class="number">0</span>]</span><br><span class="line">    module_list = nn.ModuleList()</span><br><span class="line">    prev_filters = <span class="number">3</span><span class="comment">#图片信道数为3</span></span><br><span class="line">    output_filters = []<span class="comment">#每层卷积核个数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#检查每个block的类型，创建成module加到module_list中</span></span><br><span class="line">    <span class="keyword">for</span> index,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(blocks[<span class="number">1</span>:]):</span><br><span class="line">        module = nn.Sequential()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;convolutional&#x27;</span>:</span><br><span class="line">            activation = x[<span class="string">&#x27;activation&#x27;</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                batch_normalize = <span class="built_in">int</span>(x[<span class="string">&#x27;batch_normalize&#x27;</span>])</span><br><span class="line">                bias = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                batch_normalize = <span class="number">0</span></span><br><span class="line">                </span><br><span class="line">                bias = <span class="literal">True</span></span><br><span class="line">            </span><br><span class="line">            filters = <span class="built_in">int</span>(x[<span class="string">&#x27;filters&#x27;</span>])</span><br><span class="line">            padding = <span class="built_in">int</span>(x[<span class="string">&#x27;pad&#x27;</span>])</span><br><span class="line">            kernel_size = <span class="built_in">int</span>(x[<span class="string">&#x27;size&#x27;</span>])</span><br><span class="line">            stride = <span class="built_in">int</span>(x[<span class="string">&#x27;stride&#x27;</span>])</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> padding:</span><br><span class="line">                pad = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pad = <span class="number">0</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#添加卷积层</span></span><br><span class="line">            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)</span><br><span class="line">            module.add_module(<span class="string">&quot;conv_&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(index),conv)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#添加Batch norm 层</span></span><br><span class="line">            <span class="keyword">if</span> batch_normalize:</span><br><span class="line">                bn = nn.BatchNorm2d(filters)</span><br><span class="line">                module.add_module(<span class="string">&#x27;batch_norm_&#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(index),bn)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#添加非线性激活函数</span></span><br><span class="line">            <span class="keyword">if</span> activation == <span class="string">&#x27;leaky&#x27;</span>:</span><br><span class="line">                activn = nn.LeakyReLU(<span class="number">0.1</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">                module.add_module(<span class="string">&#x27;leaky_&#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(index), activn)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;upsample&#x27;</span>:<span class="comment">#上采样层</span></span><br><span class="line">            stride = <span class="built_in">int</span>(x[<span class="string">&#x27;stride&#x27;</span>])</span><br><span class="line">            upsample = nn.Upsample(scale_factor = <span class="number">2</span>, mode = <span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">            module.add_module(<span class="string">&#x27;upsample_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(index),upsample)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;route&#x27;</span>:</span><br><span class="line">            x[<span class="string">&#x27;layers&#x27;</span>] = x[<span class="string">&#x27;layers&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">            start = <span class="built_in">int</span>(x[<span class="string">&#x27;layers&#x27;</span>][<span class="number">0</span>])</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                end = <span class="built_in">int</span>(x[<span class="string">&#x27;layers&#x27;</span>][<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                end = <span class="number">0</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> start &gt; <span class="number">0</span>:</span><br><span class="line">                start = start - index</span><br><span class="line">            <span class="keyword">if</span> end &gt; <span class="number">0</span>:</span><br><span class="line">                end = end - index</span><br><span class="line">            </span><br><span class="line">            route = EmptyLayer()</span><br><span class="line">            module.add_module(<span class="string">&#x27;route_&#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(index), route)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> end &lt; <span class="number">0</span>:</span><br><span class="line">                filters = output_filters[index + start] + output_filters[index + end]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                filters = output_filters[index + start]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;shortcut&#x27;</span>:</span><br><span class="line">            shortcut = EmptyLayer()</span><br><span class="line">            module.add_module(<span class="string">&#x27;shortcut_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(index), shortcut)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;yolo&#x27;</span>:</span><br><span class="line">            mask = x[<span class="string">&#x27;mask&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            mask = [<span class="built_in">int</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> mask]</span><br><span class="line">            </span><br><span class="line">            anchors = x[<span class="string">&#x27;anchors&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            anchors = [<span class="built_in">int</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> anchors]</span><br><span class="line">            anchors = [(anchors[i], anchors[i+<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(anchors), <span class="number">2</span>)]</span><br><span class="line">            </span><br><span class="line">            anchors = [anchors[i] <span class="keyword">for</span> i <span class="keyword">in</span> mask]</span><br><span class="line">            </span><br><span class="line">            detection = DetectionLayer(anchors)</span><br><span class="line">            module.add_module(<span class="string">&#x27;Detection_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(index), detection)</span><br><span class="line">        </span><br><span class="line">        module_list.append(module)</span><br><span class="line">        prev_filters = filters</span><br><span class="line">        output_filters.append(filters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (net_info, module_list)</span><br><span class="line"><span class="comment">#空层，用于中间层的堆叠</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmptyLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(EmptyLayer, self).__init__()</span><br><span class="line"><span class="comment">#主干网络的输出层</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetectionLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, anchors</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DetectionLayer, self).__init__()</span><br><span class="line">        self.anchors = anchors</span><br></pre></td></tr></table></figure>

<p>搭建yolov3模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Darknet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfgfile</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Darknet, self).__init__()</span><br><span class="line">        self.blocks = parse_cfg(cfgfile)</span><br><span class="line">        self.net_info, self.module_list = create_modules(self.blocks)</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x,CUDA</span>):</span></span><br><span class="line">        modules = self.blocks[<span class="number">1</span>:]</span><br><span class="line">        outputs = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        write = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, module <span class="keyword">in</span> <span class="built_in">enumerate</span>(modules):</span><br><span class="line">            module_type = (module[<span class="string">&#x27;type&#x27;</span>])</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> module_type == <span class="string">&#x27;convolutional&#x27;</span> <span class="keyword">or</span> module_type == <span class="string">&#x27;upsample&#x27;</span>:</span><br><span class="line">                x = self.module_list[i](x)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">elif</span> module_type == <span class="string">&#x27;route&#x27;</span>:</span><br><span class="line">                layers = module[<span class="string">&#x27;layers&#x27;</span>]</span><br><span class="line">                layers = [<span class="built_in">int</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> layers]</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (layers[<span class="number">0</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">                    layers[<span class="number">0</span>] = layers[<span class="number">0</span>] - i</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(layers) == <span class="number">1</span>:</span><br><span class="line">                    x = outputs[i + (layers[<span class="number">0</span>])]</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> (layers[<span class="number">1</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">                        layers[<span class="number">1</span>] = layers[<span class="number">1</span>] - i</span><br><span class="line">                    </span><br><span class="line">                    map1 = outputs[i + layers[<span class="number">0</span>]]</span><br><span class="line">                    map2 = outputs[i + layers[<span class="number">1</span>]]</span><br><span class="line">                    </span><br><span class="line">                    x = torch.cat((map1,map2), <span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">elif</span> module_type == <span class="string">&#x27;shortcut&#x27;</span>:</span><br><span class="line">                from_ = <span class="built_in">int</span>(module[<span class="string">&#x27;from&#x27;</span>])</span><br><span class="line">                x = outputs[i-<span class="number">1</span>] + outputs[i+from_]</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">            <span class="keyword">elif</span> module_type == <span class="string">&#x27;yolo&#x27;</span>:</span><br><span class="line">                    </span><br><span class="line">                anchors = self.module_list[i][<span class="number">0</span>].anchors</span><br><span class="line">                <span class="comment">#获得输入维度</span></span><br><span class="line">                inp_dim = <span class="built_in">int</span>(self.net_info[<span class="string">&#x27;height&#x27;</span>])</span><br><span class="line">                    </span><br><span class="line">                <span class="comment">#获得分类个数</span></span><br><span class="line">                num_classes = <span class="built_in">int</span>(module[<span class="string">&#x27;classes&#x27;</span>])</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">                <span class="comment">#转换</span></span><br><span class="line">                x = x.data</span><br><span class="line">                x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> write:</span><br><span class="line">                    detections = x</span><br><span class="line">                    write = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    detections = torch.cat((detections, x), <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            outputs[i] = x</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> detections</span><br><span class="line">    <span class="comment">#载入权重文件</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span>(<span class="params">self, wightfile</span>):</span></span><br><span class="line">        </span><br><span class="line">        fp = <span class="built_in">open</span>(wightfile, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#前五行是头部信息</span></span><br><span class="line">        <span class="comment">#1.最高版本</span></span><br><span class="line">        <span class="comment">#2.最低版本</span></span><br><span class="line">        <span class="comment">#3.Subversion number</span></span><br><span class="line">        <span class="comment">#4，5.Images seen by the network (during training)</span></span><br><span class="line">        header = np.fromfile(fp,dtype = np.int32, count = <span class="number">5</span>)</span><br><span class="line">        self.header = torch.from_numpy(header)</span><br><span class="line">        self.seen = self.header[<span class="number">3</span>]</span><br><span class="line">        </span><br><span class="line">        weights = np.fromfile(fp,dtype = np.float32)</span><br><span class="line">        </span><br><span class="line">        ptr = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.module_list)):</span><br><span class="line">            module_type = self.blocks[i+<span class="number">1</span>][<span class="string">&#x27;type&#x27;</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> module_type == <span class="string">&#x27;convolutional&#x27;</span>:</span><br><span class="line">                model = self.module_list[i]</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    batch_normalize = <span class="built_in">int</span>(self.blocks[i+<span class="number">1</span>][<span class="string">&#x27;batch_normalize&#x27;</span>])</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    batch_normalize = <span class="number">0</span></span><br><span class="line">                </span><br><span class="line">                conv = model[<span class="number">0</span>]</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> batch_normalize:</span><br><span class="line">                    bn = model[<span class="number">1</span>]</span><br><span class="line">                    <span class="comment">#获得批量规格化层的权重数量</span></span><br><span class="line">                    num_bn_biases = bn.bias.numel()</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#载入权重</span></span><br><span class="line">                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])</span><br><span class="line">                    ptr += num_bn_biases</span><br><span class="line">                </span><br><span class="line">                    bn_weights = torch.from_numpy(weights[ptr:ptr + num_bn_biases])</span><br><span class="line">                    ptr += num_bn_biases</span><br><span class="line">                </span><br><span class="line">                    bn_running_mean = torch.from_numpy(weights[ptr:ptr + num_bn_biases])</span><br><span class="line">                    ptr += num_bn_biases</span><br><span class="line">                </span><br><span class="line">                    bn_running_var = torch.from_numpy(weights[ptr:ptr + num_bn_biases])</span><br><span class="line">                    ptr += num_bn_biases</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#将载入的数据转换成模型权重的维度</span></span><br><span class="line">                    bn_biases = bn_biases.view_as(bn.bias.data)</span><br><span class="line">                    bn_weights = bn_weights.view_as(bn.weight.data)</span><br><span class="line">                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)</span><br><span class="line">                    bn_running_var = bn_running_var.view_as(bn.running_var)</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#复制到模型里</span></span><br><span class="line">                    bn.bias.data.copy_(bn_biases)</span><br><span class="line">                    bn.weight.data.copy_(bn_weights)</span><br><span class="line">                    bn.running_mean.copy_(bn_running_mean)</span><br><span class="line">                    bn.running_var.copy_(bn_running_var)</span><br><span class="line">            </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment">#没有批量规格化层时只要载入卷积层的偏差</span></span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#偏差的数量</span></span><br><span class="line">                    num_biases = conv.bias.numel()</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#加载权重</span></span><br><span class="line">                    conv_biases = torch.from_numpy(weights[ptr:ptr + num_biases])</span><br><span class="line">                    ptr += num_biases</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#更改维度</span></span><br><span class="line">                    conv_biases = conv_biases.view_as(conv.bias.data)</span><br><span class="line">                </span><br><span class="line">                    <span class="comment">#复制到模型里</span></span><br><span class="line">                    conv.bias.data.copy_(conv_biases)</span><br><span class="line">            </span><br><span class="line">                <span class="comment">#加载卷积层的权重</span></span><br><span class="line">                num_weights = conv.weight.numel()</span><br><span class="line">            </span><br><span class="line">                conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])</span><br><span class="line">                ptr += num_weights</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">                conv_weights = conv_weights.view_as(conv.weight.data)</span><br><span class="line">                </span><br><span class="line">                conv.weight.data.copy_(conv_weights)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出转换函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#采用检测特征图并将其转换为二维张量，每一行对应于边界框的属性</span></span><br><span class="line"><span class="comment">#原特征图 按行 每个方格 三个边界框</span></span><br><span class="line"><span class="comment">#参数：预测输出，输入图像维度，anchors，分类个数，cuda</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_transform</span>(<span class="params">prediction, inp_dim, anchors, num_classes, CUDA = <span class="literal">True</span></span>):</span></span><br><span class="line">    batch_size = prediction.size(<span class="number">0</span>)</span><br><span class="line">    stride = inp_dim // prediction.size(<span class="number">2</span>)</span><br><span class="line">    grid_size = inp_dim // stride</span><br><span class="line">    bbox_attrs = <span class="number">5</span> + num_classes</span><br><span class="line">    num_anchors = <span class="built_in">len</span>(anchors)</span><br><span class="line">    prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)</span><br><span class="line">    prediction = prediction.transpose(<span class="number">1</span>,<span class="number">2</span>).contiguous()</span><br><span class="line">    prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)</span><br><span class="line">    </span><br><span class="line">    anchors = [(a[<span class="number">0</span>]/stride, a[<span class="number">1</span>]/stride) <span class="keyword">for</span> a <span class="keyword">in</span> anchors]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#对目标置信度和中心坐标进行sigmoid化</span></span><br><span class="line">    prediction[:,:,<span class="number">0</span>] = torch.sigmoid(prediction[:,:,<span class="number">0</span>])</span><br><span class="line">    prediction[:,:,<span class="number">1</span>] = torch.sigmoid(prediction[:,:,<span class="number">1</span>])</span><br><span class="line">    prediction[:,:,<span class="number">4</span>] = torch.sigmoid(prediction[:,:,<span class="number">4</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#网格偏移</span></span><br><span class="line">    grid = np.arange(grid_size)</span><br><span class="line">    a,b = np.meshgrid(grid,grid)</span><br><span class="line">    </span><br><span class="line">    x_offset = torch.FloatTensor(a).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    y_offset = torch.FloatTensor(b).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> CUDA:</span><br><span class="line">        x_offset = x_offset.cuda()</span><br><span class="line">        y_offset = y_offset.cuda()</span><br><span class="line">    </span><br><span class="line">    x_y_offset = torch.cat((x_offset, y_offset), <span class="number">1</span>).repeat(<span class="number">1</span>,num_anchors).view(-<span class="number">1</span>,<span class="number">2</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    prediction[:,:,:<span class="number">2</span>] += x_y_offset</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#转换到对数空间</span></span><br><span class="line">    anchors = torch.FloatTensor(anchors)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> CUDA:</span><br><span class="line">        anchors = anchors.cuda()</span><br><span class="line">    </span><br><span class="line">    anchors = anchors.repeat(grid_size*grid_size, <span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    prediction[:,:,<span class="number">2</span>:<span class="number">4</span>] = torch.exp(prediction[:,:,<span class="number">2</span>:<span class="number">4</span>])*anchors</span><br><span class="line">    </span><br><span class="line">    prediction[:,:,<span class="number">5</span>:(<span class="number">5</span>+num_classes)] = torch.sigmoid((prediction[:,:,<span class="number">5</span>:(<span class="number">5</span>+num_classes)]))</span><br><span class="line">    </span><br><span class="line">    prediction[:,:,:<span class="number">4</span>] *= stride</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure>

<p>过滤置信度低的预测和非极大值抑制函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#客观分数阈值处理和非极大抑制</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_results</span>(<span class="params">prediction, confidence, num_classes, nms_conf = <span class="number">0.4</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    conf_mask = (prediction[:,:,<span class="number">4</span>] &gt; confidence).<span class="built_in">float</span>().unsqueeze(<span class="number">2</span>)</span><br><span class="line">    prediction = prediction*conf_mask</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#执行非极大值抑制</span></span><br><span class="line">    <span class="comment">#现在拥有边界框的中心坐标和高度宽度，转换为对角点比较容易计算IoU</span></span><br><span class="line">    <span class="comment">#(center x,center y, height, width)-&gt;(左上角x, 左上角y, 右下角x, 右下角y)</span></span><br><span class="line">    box_corner = prediction.new(prediction.shape)</span><br><span class="line">    box_corner[:,:,<span class="number">0</span>] = (prediction[:,:,<span class="number">0</span>] - prediction[:,:,<span class="number">2</span>]/<span class="number">2</span>)</span><br><span class="line">    box_corner[:,:,<span class="number">1</span>] = (prediction[:,:,<span class="number">1</span>] - prediction[:,:,<span class="number">3</span>]/<span class="number">2</span>)</span><br><span class="line">    box_corner[:,:,<span class="number">2</span>] = (prediction[:,:,<span class="number">0</span>] + prediction[:,:,<span class="number">2</span>]/<span class="number">2</span>)</span><br><span class="line">    box_corner[:,:,<span class="number">3</span>] = (prediction[:,:,<span class="number">1</span>] + prediction[:,:,<span class="number">3</span>]/<span class="number">2</span>)</span><br><span class="line">    prediction[:,:,:<span class="number">4</span>] = box_corner[:,:,:<span class="number">4</span>]</span><br><span class="line">    </span><br><span class="line">    batch_size = prediction.size(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    write = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">        image_pred = prediction[ind]</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#取80个分类最大的分数和下标</span></span><br><span class="line">        max_conf, max_conf_score = torch.<span class="built_in">max</span>(image_pred[:,<span class="number">5</span>:<span class="number">5</span>+num_classes], <span class="number">1</span>)</span><br><span class="line">        max_conf = max_conf.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)</span><br><span class="line">        max_conf_score = max_conf_score.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)</span><br><span class="line">        seq = (image_pred[:,:<span class="number">5</span>], max_conf, max_conf_score)</span><br><span class="line">        image_pred = torch.cat(seq, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#去除置信度小于confidence的边界框</span></span><br><span class="line">        non_zero_ind = (torch.nonzero(image_pred[:,<span class="number">4</span>]))</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> image_pred_.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获得图像中检测到的类</span></span><br><span class="line">        img_classes = unique(image_pred_[:,-<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#按类别执行NMS</span></span><br><span class="line">        <span class="keyword">for</span> cls <span class="keyword">in</span> img_classes:</span><br><span class="line">            </span><br><span class="line">            cls_mask = image_pred_*(image_pred_[:,-<span class="number">1</span>] == cls).<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)</span><br><span class="line">            class_mask_ind = torch.nonzero(cls_mask[:,-<span class="number">2</span>]).squeeze()</span><br><span class="line">            image_pred_class = image_pred_[class_mask_ind].view(-<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#按照置信度排序</span></span><br><span class="line">            conf_sort_index = torch.sort(image_pred_class[:,<span class="number">4</span>], descending = <span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line">            image_pred_class = image_pred_class[conf_sort_index]</span><br><span class="line">            <span class="comment">#预测的个数</span></span><br><span class="line">            idx = image_pred_class.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#NMS</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(idx):</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    ious = bbox_iou(image_pred_class[i].unsqueeze(<span class="number">0</span>), image_pred_class[i+<span class="number">1</span>:])</span><br><span class="line">                <span class="keyword">except</span> ValueError:<span class="comment">#返回空张量</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">except</span> IndexError:<span class="comment">#地址异常</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment">#去除所有IoU大于阈值的预测</span></span><br><span class="line">                iou_mask = (ious &lt; nms_conf).<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)</span><br><span class="line">                image_pred_class[i+<span class="number">1</span>:] *= iou_mask</span><br><span class="line">                </span><br><span class="line">                non_zero_ind = torch.nonzero(image_pred_class[:,<span class="number">4</span>]).squeeze()</span><br><span class="line">                image_pred_class = image_pred_class[non_zero_ind].view(-<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line">                </span><br><span class="line">            </span><br><span class="line">            batch_ind = image_pred_class.new(image_pred_class.size(<span class="number">0</span>), <span class="number">1</span>).fill_(ind)</span><br><span class="line">            seq = batch_ind, image_pred_class</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> write:</span><br><span class="line">                output = torch.cat(seq, <span class="number">1</span>)</span><br><span class="line">                write = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                out = torch.cat(seq, <span class="number">1</span>)</span><br><span class="line">                output = torch.cat((output,out))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>计算tenser中不同的值个数函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unique</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    tensor_np = tensor.cpu().numpy()</span><br><span class="line">    unique_np = np.unique(tensor_np)</span><br><span class="line">    unique_tensor = torch.from_numpy(unique_np)</span><br><span class="line">    </span><br><span class="line">    tensor_res = tensor.new(unique_tensor.shape)</span><br><span class="line">    tensor_res.copy_(unique_tensor)</span><br><span class="line">    <span class="keyword">return</span> tensor_res</span><br></pre></td></tr></table></figure>

<p>计算交并比的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算box1与box2中所有边界框的IoU</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bbox_iou</span>(<span class="params">box1, box2</span>):</span></span><br><span class="line">    <span class="comment">#边界框的坐标</span></span><br><span class="line">    b1_x1,b1_y1,b1_x2,b1_y2 = box1[:,<span class="number">0</span>],box1[:,<span class="number">1</span>],box1[:,<span class="number">2</span>],box1[:,<span class="number">3</span>]</span><br><span class="line">    b2_x1,b2_y1,b2_x2,b2_y2 = box2[:,<span class="number">0</span>],box2[:,<span class="number">1</span>],box2[:,<span class="number">2</span>],box2[:,<span class="number">3</span>]</span><br><span class="line">    <span class="comment">#相交矩形的坐标</span></span><br><span class="line">    inter_rect_x1 = torch.<span class="built_in">max</span>(b1_x1,b2_x1)</span><br><span class="line">    inter_rect_y1 = torch.<span class="built_in">max</span>(b1_y1,b2_y1)</span><br><span class="line">    inter_rect_x2 = torch.<span class="built_in">min</span>(b1_x2,b2_x2)</span><br><span class="line">    inter_rect_y2 = torch.<span class="built_in">min</span>(b1_y2,b2_y2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#相交面积</span></span><br><span class="line">    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + <span class="number">1</span>, <span class="built_in">min</span>=<span class="number">0</span>) * torch.clamp(inter_rect_y2 - inter_rect_y1 + <span class="number">1</span>, <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#并集面积</span></span><br><span class="line">    b1_area = (b1_x2 - b1_x1 + <span class="number">1</span>)*(b1_y2 - b1_y1 + <span class="number">1</span>)</span><br><span class="line">    b2_area = (b2_x2 - b2_x1 + <span class="number">1</span>)*(b2_y2 - b2_y1 + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    iou = inter_area / (b1_area + b2_area - inter_area)</span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>

<p>以上就是yolov3的主体部分，不过由于输入的图片维度固定是$416\times 416$​​​，并且opencv读取图片的信道顺序与网络权重文件的训练顺序不同，需要对图片进行预处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用填充，在不改变图片纵横比的前提下改变图片大小</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterbox_image</span>(<span class="params">img,inp_dim</span>):</span></span><br><span class="line">    </span><br><span class="line">    img_w, img_h = img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]</span><br><span class="line">    w, h = inp_dim</span><br><span class="line">    </span><br><span class="line">    new_w = <span class="built_in">int</span>(img_w * <span class="built_in">min</span>(w/img_w, h/img_h))</span><br><span class="line">    new_h = <span class="built_in">int</span>(img_h * <span class="built_in">min</span>(w/img_w, h/img_h))</span><br><span class="line">    </span><br><span class="line">    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)</span><br><span class="line">    </span><br><span class="line">    canvas = np.full((inp_dim[<span class="number">1</span>], inp_dim[<span class="number">0</span>], <span class="number">3</span>), <span class="number">128</span>)</span><br><span class="line">    </span><br><span class="line">    canvas[(h-new_h)//<span class="number">2</span>:(h-new_h)//<span class="number">2</span>+new_h,(w-new_w)//<span class="number">2</span>:(w-new_w)//<span class="number">2</span>+new_w,:] = resized_image</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> canvas</span><br><span class="line"></span><br><span class="line"><span class="comment">#信道顺序从BGR转变为RGB</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prep_image</span>(<span class="params">img, inp_dim</span>):</span></span><br><span class="line">    img = letterbox_image(img, (inp_dim, inp_dim))</span><br><span class="line">    <span class="comment">#返回Variable</span></span><br><span class="line">    img = cv2.resize(img,(inp_dim,inp_dim))</span><br><span class="line">    img = img[:,:,::-<span class="number">1</span>].transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)).copy()</span><br><span class="line">    img = torch.from_numpy(img).<span class="built_in">float</span>().div(<span class="number">255.0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<p>读取coco数据集中的类名函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_classes</span>(<span class="params">namesfile</span>):</span></span><br><span class="line">    fp = <span class="built_in">open</span>(namesfile, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    names = fp.read().split(<span class="string">&#x27;\n&#x27;</span>)[:-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> names</span><br></pre></td></tr></table></figure>

<p>最后将预测结果画在原图上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画出边界框</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span>(<span class="params">x, results</span>):</span></span><br><span class="line">    c1 = <span class="built_in">tuple</span>(x[<span class="number">1</span>:<span class="number">3</span>].<span class="built_in">int</span>())</span><br><span class="line">    c2 = <span class="built_in">tuple</span>(x[<span class="number">3</span>:<span class="number">5</span>].<span class="built_in">int</span>())</span><br><span class="line">    c1 = <span class="built_in">tuple</span>([<span class="built_in">int</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> c1])</span><br><span class="line">    c2 = <span class="built_in">tuple</span>([<span class="built_in">int</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> c2])</span><br><span class="line">    </span><br><span class="line">    img = results[<span class="built_in">int</span>(x[<span class="number">0</span>])]</span><br><span class="line">    cls = <span class="built_in">int</span>(x[-<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    label = <span class="string">&#x27;&#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(classes[cls])</span><br><span class="line">    cv2.rectangle(img,c1,c2,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">1</span>)</span><br><span class="line">    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, <span class="number">1</span>, <span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    c2 = c1[<span class="number">0</span>] + t_size[<span class="number">0</span>] + <span class="number">3</span>,c1[<span class="number">1</span>] + t_size[<span class="number">1</span>] + <span class="number">4</span></span><br><span class="line">    cv2.rectangle(img,c1,c2,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),-<span class="number">1</span>)</span><br><span class="line">    cv2.putText(img,label,(c1[<span class="number">0</span>],c1[<span class="number">1</span>]+t_size[<span class="number">1</span>]+<span class="number">4</span>), cv2.FONT_HERSHEY_PLAIN, <span class="number">1</span>, [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>], <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<p>linux下框架文件下载：</p>
<p>配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg</span><br></pre></td></tr></table></figure>

<p>测试图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png</span><br></pre></td></tr></table></figure>

<p>预训练权重</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://pjreddie.com/media/files/yolov3.weights</span><br></pre></td></tr></table></figure>

<p>COCO数据集中的对象名称：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names</span><br></pre></td></tr></table></figure>



<p>测试图片：</p>
<p><img src="/2021/08/17/yolov3/dog-cycle-car.png" alt="dog-cycle-car"></p>
<p>检测结果：</p>
<p><img src="/2021/08/17/yolov3/dev_dog-cycle-car.png" alt="dev_dog-cycle-car"></p>
<hr>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44791964/article/details/105310627">睿智的目标检测26——Pytorch搭建yolo3目标检测平台</a></p>
<p>并且还有配套视频<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Hp4y1y788">Pytorch 搭建自己的YOLO3目标检测平台（Bubbliiiing 深度学习 教程）</a></p>
<p>这篇文章的想法是根据yolov3的模型，手动创建一个网络模型，因为yolov3中的残差块相似度很高，基本都在重复利用，所以手动实现起来并不是非常繁琐。在外部网络的传播中所用的结构也很类似，堆叠时可以在forward函数中手动进行。</p>
<p><img src="/2021/08/17/yolov3/2.jpg" alt="2"></p>
<p>这就是yolov3网络的一个基本模型，主干网络是Darknet-53。</p>
<p>这幅图最下中间的数据有些错误，输出维度应该是$batch_size \times 13\times 13\times 512$。</p>
<p>根据上图，构建YOLOv3网络模型。</p>
<p>残差块结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#残差块</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_channel</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResidualBlock, self).__init__()</span><br><span class="line">        <span class="comment">#1*1卷积通道数降低一半，维度不变</span></span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channel, input_channel // <span class="number">2</span>, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(input_channel // <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="comment">#3*3卷积通道变成2倍，维度不变</span></span><br><span class="line">        self.seq2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channel // <span class="number">2</span>, input_channel, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(input_channel),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line">        </span><br><span class="line">        x = self.seq1(x)</span><br><span class="line">        x = self.seq2(x)</span><br><span class="line">        x += residual</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>



<p>Darknet-53</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#主干网络结构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Darknet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layers=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">4</span>]</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Darknet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="comment">#416*416*32 -&gt; 208*208*64</span></span><br><span class="line">        self.layer1 = self.make_layer(<span class="number">32</span>,layers[<span class="number">0</span>])</span><br><span class="line">        <span class="comment">#208*208*64 -&gt; 104*104*128</span></span><br><span class="line">        self.layer2 = self.make_layer(<span class="number">64</span>,layers[<span class="number">1</span>])</span><br><span class="line">        <span class="comment">#104*104*128 -&gt; 52*52*256</span></span><br><span class="line">        self.layer3 = self.make_layer(<span class="number">128</span>,layers[<span class="number">2</span>])</span><br><span class="line">        <span class="comment">#52*52*256 -&gt; 26*26*512</span></span><br><span class="line">        self.layer4 = self.make_layer(<span class="number">256</span>,layers[<span class="number">3</span>])</span><br><span class="line">        <span class="comment">#26*26*512 -&gt; 13*13*1024</span></span><br><span class="line">        self.layer5 = self.make_layer(<span class="number">512</span>,layers[<span class="number">4</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#主干网络中的一块</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_layer</span>(<span class="params">self, input_channel, num_blocks</span>):</span></span><br><span class="line">        modules = nn.Sequential()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下采样</span></span><br><span class="line">        modules.add_module(<span class="string">&#x27;ds_conv&#x27;</span>, nn.Conv2d(input_channel, input_channel*<span class="number">2</span>, <span class="number">3</span>, stride=<span class="number">2</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>))</span><br><span class="line">        modules.add_module(<span class="string">&#x27;ds_norm&#x27;</span>, nn.BatchNorm2d(input_channel*<span class="number">2</span>))</span><br><span class="line">        modules.add_module(<span class="string">&#x27;ds_relu&#x27;</span>, nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            residual_input = input_channel*<span class="number">2</span></span><br><span class="line">            modules.add_module(<span class="string">&#x27;residual_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i), ResidualBlock(residual_input))</span><br><span class="line">        <span class="keyword">return</span> modules</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        </span><br><span class="line">        x = self.seq1(x)</span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        <span class="comment">#52*52*256</span></span><br><span class="line">        out1 = self.layer3(x)</span><br><span class="line">        <span class="comment">#26*26*512</span></span><br><span class="line">        out2 = self.layer4(out1)</span><br><span class="line">        <span class="comment">#13*13*1024</span></span><br><span class="line">        out3 = self.layer5(out2)</span><br><span class="line">        <span class="keyword">return</span> out1,out2,out3</span><br></pre></td></tr></table></figure>



<p>组建总体网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLOv3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(YOLOv3, self).__init__()</span><br><span class="line">        self.backbone = Darknet()</span><br><span class="line">        <span class="comment">#三个先验框</span></span><br><span class="line">        self.anchors1 = [(<span class="number">116</span>,<span class="number">90</span>),(<span class="number">156</span>,<span class="number">198</span>),(<span class="number">373</span>,<span class="number">326</span>)]</span><br><span class="line">        self.anchors2 = [(<span class="number">30</span>,<span class="number">61</span>),(<span class="number">62</span>,<span class="number">45</span>),(<span class="number">59</span>,<span class="number">119</span>)]</span><br><span class="line">        self.anchors3 = [(<span class="number">10</span>,<span class="number">13</span>),(<span class="number">16</span>,<span class="number">30</span>),(<span class="number">33</span>,<span class="number">23</span>)]</span><br><span class="line">        <span class="comment">#识别对象数量</span></span><br><span class="line">        self.num_class = <span class="number">80</span></span><br><span class="line">        <span class="comment">#输入维度</span></span><br><span class="line">        self.in_dim = <span class="number">416</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#检测层前的处理</span></span><br><span class="line">        self.block1 = self.block_5L(<span class="number">1024</span>,<span class="number">512</span>)</span><br><span class="line">        self.block2 = self.block_5L(<span class="number">768</span>,<span class="number">256</span>)</span><br><span class="line">        self.block3 = self.block_5L(<span class="number">384</span>,<span class="number">128</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#检测层</span></span><br><span class="line">        self.output1 = self.output_layer(<span class="number">512</span>, <span class="number">255</span>)</span><br><span class="line">        self.output2 = self.output_layer(<span class="number">256</span>, <span class="number">255</span>)</span><br><span class="line">        self.output3 = self.output_layer(<span class="number">128</span>, <span class="number">255</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#上采样</span></span><br><span class="line">        self.conv_up1 = self.conv_up(<span class="number">512</span>)</span><br><span class="line">        self.conv_up2 = self.conv_up(<span class="number">256</span>)</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">block_5L</span>(<span class="params">self, input_channel, output_channel</span>):</span></span><br><span class="line">        seq = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channel, output_channel, <span class="number">1</span>, stride=<span class="number">1</span>,padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(output_channel, output_channel*<span class="number">2</span>, <span class="number">3</span>, stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel*<span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(output_channel*<span class="number">2</span>, output_channel, <span class="number">1</span>, stride=<span class="number">1</span>,padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(output_channel, output_channel*<span class="number">2</span>, <span class="number">3</span>, stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel*<span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(output_channel*<span class="number">2</span>, output_channel, <span class="number">1</span>, stride=<span class="number">1</span>,padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">            </span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> seq</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_layer</span>(<span class="params">self, input_channel, output_channel</span>):</span></span><br><span class="line">        seq = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channel, input_channel*<span class="number">2</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(input_channel*<span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(input_channel*<span class="number">2</span>, output_channel, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channel),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> seq</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv_up</span>(<span class="params">self, input_channel</span>):</span></span><br><span class="line">        seq = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channel, input_channel // <span class="number">2</span>, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(input_channel // <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.1</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> seq</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment">#52*52*256,26*26*512,13*13*1024</span></span><br><span class="line">        out1,out2,out3 = self.backbone(x)</span><br><span class="line">        <span class="comment">#13*13*512</span></span><br><span class="line">        x = self.block1(out3)</span><br><span class="line">        <span class="comment">#13*13*255</span></span><br><span class="line">        pred1 = self.output1(x)</span><br><span class="line">        <span class="comment">#26*26*256</span></span><br><span class="line">        x = self.conv_up1(x)</span><br><span class="line">        <span class="comment">#26*26*768</span></span><br><span class="line">        x = torch.cat((out2,x), <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#26*26*256</span></span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="comment">#26*26*255</span></span><br><span class="line">        pred2 = self.output2(x)</span><br><span class="line">        <span class="comment">#52*52*128</span></span><br><span class="line">        x = self.conv_up2(x)</span><br><span class="line">        <span class="comment">#52*52*384</span></span><br><span class="line">        x = torch.cat((out1,x), <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#52*52*128</span></span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        <span class="comment">#52*52*255</span></span><br><span class="line">        pred3 = self.output3(x)</span><br><span class="line">        <span class="comment">#13*13*255+26*26*255+52*52*255 -&gt; 10647*85</span></span><br><span class="line">        </span><br><span class="line">        prediction = resize_pred(pred1,self.anchors1,self.in_dim,self.num_class)</span><br><span class="line">        prediction = torch.cat((prediction,resize_pred(pred2,self.anchors2,self.in_dim,self.num_class)), <span class="number">1</span>)</span><br><span class="line">        prediction = torch.cat((prediction,resize_pred(pred3,self.anchors3,self.in_dim,self.num_class)), <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure>



<p>检测数据转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#13*13*255,26*26*255,52*52*255 -&gt; 10647*85</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_pred</span>(<span class="params">pred, anchors, in_dim, num_class</span>):</span></span><br><span class="line">    </span><br><span class="line">    batch_size = pred.shape[<span class="number">0</span>]</span><br><span class="line">    pred_dim = pred.shape[<span class="number">2</span>]</span><br><span class="line">    num_anchor = <span class="built_in">len</span>(anchors)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#第二维度是一个先验框的预测</span></span><br><span class="line">    <span class="comment">#batch_size,255,13,13 -&gt; batch_size,255,13*13</span></span><br><span class="line">    pred = pred.view(batch_size,num_anchor*(<span class="number">5</span>+num_class), pred_dim*pred_dim)</span><br><span class="line">    <span class="comment">#batch_size,255,13*13 -&gt; batch_size,13*13,255</span></span><br><span class="line">    pred = pred.transpose(<span class="number">1</span>,<span class="number">2</span>).contiguous()</span><br><span class="line">    <span class="comment">#batch_size,13*13,255 -&gt; batch_size,13*13*3,85</span></span><br><span class="line">    pred = pred.view(batch_size, pred_dim*pred_dim*num_anchor, <span class="number">5</span>+num_class)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#sigmoid化中心坐标和置信度</span></span><br><span class="line">    pred[:,:,<span class="number">0</span>] = torch.sigmoid(pred[:,:,<span class="number">0</span>])</span><br><span class="line">    pred[:,:,<span class="number">1</span>] = torch.sigmoid(pred[:,:,<span class="number">1</span>])</span><br><span class="line">    pred[:,:,<span class="number">4</span>] = torch.sigmoid(pred[:,:,<span class="number">4</span>])</span><br><span class="line">    pred[:,:,<span class="number">5</span>:<span class="number">5</span>+num_anchor] = torch.sigmoid(pred[:,:,<span class="number">5</span>:<span class="number">5</span>+num_anchor])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#中心坐标加上偏移</span></span><br><span class="line">    grid = np.arange(pred_dim)</span><br><span class="line">    x_offset,y_offset = np.meshgrid(grid,grid)</span><br><span class="line">    </span><br><span class="line">    x_offset = torch.FloatTensor(x_offset).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    y_offset = torch.FloatTensor(y_offset).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    offset = torch.cat((x_offset,y_offset), <span class="number">1</span>).repeat(<span class="number">1</span>,num_anchor).view(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    pred[:,:,:<span class="number">2</span>] += offset</span><br><span class="line">    stride = in_dim // pred.shape[<span class="number">1</span>]</span><br><span class="line">    pred[:,:,:<span class="number">2</span>] *= stride</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#处理高、宽</span></span><br><span class="line">    anchors = torch.FloatTensor(anchors).repeat(pred_dim*pred_dim, <span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    pred[:,:,<span class="number">2</span>:<span class="number">4</span>] = torch.exp(pred[:,:,<span class="number">2</span>:<span class="number">4</span>])*anchors</span><br><span class="line">    <span class="keyword">return</span> pred</span><br></pre></td></tr></table></figure>

<p>这是整个网络模型，只能得到维度正确的网络输出，还没有对输出的进一步处理以及网络权重的加载或者训练模型的部分。</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>John Doe</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://example.com/2021/08/17/yolov3/">http://example.com/2021/08/17/yolov3/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Do you believe in <strong>DESTINY</strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/YOLO/"># YOLO</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2021/08/19/Win7%E5%AE%89%E8%A3%85VM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%90%AD%E5%BB%BALinux%E7%8E%AF%E5%A2%83/">Win7安装VM虚拟机搭建Linux环境</a>
            
            
            <a class="next" rel="next" href="/2021/08/12/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-3/">卷积神经网络-3</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© John Doe | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>